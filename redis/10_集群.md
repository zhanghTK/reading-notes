## 节点

节点：运行在集群模式下的 Redis 服务器（启动集群模式：cluster-enabled 配置）

节点连接前都是独立节点，连接（握手，成功）后成为集群，集群命令：
- CLUSTER MEET <ip> <port>：节点连接命令
- CLUSTER NODES：节点查看
- CLUSTER INFO：
- CLUSTER ADDSLOTS：将槽指派给节点
- CLUSTER GETKEYSINSLOT <slot> <count>：返回最多 count 个属于槽 slot 的数据库键
- CLUSTER REPLICATE <node_id>：指定本节点为 node_id 节点的从节点

### 集群数据结构

#### clusterNode

clusterNode 结构保存一个节点的当前状态（只有在集群模式下使用的数据）

节点中保存自己及集群中其他节点的状态（clusterNode）

clusterNode 中定义的主要字段：

unsigned char slots[16384/8]：二进制位数组，以位图形式记录单个节点处理哪些槽
int numslot：节点处理槽的数量
struct clusterNode *slaveof：如果当前节点是从节点，指向主节点
int numslaves：正在复制这个节点的从节点数量
struct clusterNode **slaves：数组，每个元素展现搞一个正在复制这个主节点的额从节点的 clusterNode 结构
list *fail_reports：记录所有其他节点对该节点的下线报告
clusterLink *link：见下面

#### clusterLink

clusterLink 结构保存连接节点所需的有关信息，如套接字描述符，IO缓冲区

#### clusterState

每个节都保存一个 clusterState 结构，记录当前节点视角下集群所处状态，主要字段：

dict * nodes：集群节点名单，键为节点名称，值为 clusterNode 结构
clusterNode *slots[16384]：记录集群所有槽的指派信息
clusterNode *myself：当前的 clusterNode 节点
zskiplist *slots_to_key：跳跃表保存槽和键之间关系
clusterNode *importing_slots_from[16384]：记录当前节点正在从其他节点导入槽
clusterNode *migrating_slots_to[16384]：记录当前节点正在迁移至其他节点槽

### CLUSTER MEET 命令

A -> B : CLUSTER MEET 的握手过程（类似与 TCP 三次握手）：
1. 节点A 为节点B 创建 clusterNode 结构，并添加到自己的 clusterState.nodes
2. 向节点B 发送 MEET 消息
3. 节点B 为节点A 创建 clusterNode 结构，并添加到自己的 clusterState.nodes
4. 节点B 向 节点A 返回 PONG
5. 节点A 收到 节点B，并发送 PONG （A 确认知道 B 已添加）
6. 节点B 收到 PONG，握手完成 （B 确认知道 A 已知道）

A，B 握手结束后，A 将 B 的信息通过 Gossip 协议传播给集群中其它节点，其它节点与 B 进行握手

## 槽指派

集群的整个数据库被分为 16384 个槽，每个键属于其中一个槽，每个节点可以处理 [0, 16384] 个槽

集群的状态：
- 上线：所有槽都有节点在处理
- 下线：任何一个槽没有得到处理

### 记录节点的槽指派信息
clusterNode 结构中定义的：unsigned char slots[16384/8] 和 int numslot，说明见上面

### 传播节点的槽指派信息

将本节点处理的槽信息发送给集群中其它节点，其它节点则更新自己的 clusterState.nodes 中对应 clusterNode 中的槽信息

### 记录集群所有槽的指派信息

节点的 clusterState.slots 数组记录集群所有槽的指派信息，slots[i] 指针指向 clusterNode 或 NULL

clusterNode.slots VS clusterState.slots:
- clusterNode.slots：位图数组，记录单个节点处理哪些槽
- clusterState.slots：clusterNode 数组，记录集群槽的指派信息

### CLUSTER ADDSLOTS 命令

实现：
1. 遍历所有输入槽，检查是否满足都是未指派，不满足向客户端返回错误并终止命令
2. 遍历所有槽，更新 clusterState.slots[i] 为当前 clusterNode，更新当前 clusterNode.slots 的第 i 位

执行完后，通知集群中其它节点当前处理哪些槽

## 在集群中执行命令

![命令执行流程](http://redisbook1e-gallery.readthedocs.io/en/latest/_images/graphviz-6f36d23c96de411c52b064521b087ba8bda9ccd8.png)

- 计算键属于哪个槽,算法：CRC16(key) & 16383

- 判断槽是否由当前节点处理：需要第 i 个槽处理，判断clusterState.slots[i] 是否等于 clusterState.myself：
  - 是：由当前负责处理
  - 否：由 clusterState[i] 指向的 clusterNode 处理，向客户端返回 MOVED

- MOVED 错误，格式：MOVED <slot> <ip>:<port>，集群模式下 MOVED 被隐藏

- 节点数据库与单机数据库的区别：节点只使用 0 号数据库

  slots_to_keys 跳跃表每个节点的分值是一个槽号，而每个节点的成员都是一个数据库键（重新分片切片使用）

## 重新分片

重新分片：将 A节点（源节点）的若干槽指派给 B节点（目标节点）

重新分片实现由 redis-trib 负责执行，步骤：
![对 slot 重新分片过程](http://redisbook1e-gallery.readthedocs.io/en/latest/_images/graphviz-fe3255f5de0cbab6f74ac113827dcf4f34ea65fe.png)


键迁移过程：
![键迁移过程](http://redisbook1e-gallery.readthedocs.io/en/latest/_images/graphviz-fba74127c3849e540cea49200ee809b01f8c8a27.png)

## ACK 错误

ACK 错误：迁移过程中与客户端命令的冲突，则向客户端返回 ACK 错误（集群下 ACK 错误会被隐藏）
![判断是否发送 ACK 错误的过程](http://redisbook1e-gallery.readthedocs.io/en/latest/_images/graphviz-e2c71f49318a6636a74534d4517ffa173c27dae0.png)

- CLUSTER SETSLOT IMPORTING 命令：CLUSTER SETSLOT <i> IMPORTING  <source_id> 将更新 clusterState.importing_slots_from[i] 的值设置为 source_id 所代表节点的 clusterNode 结构

- CLUSTER SETSLOT MIGRATING 命令：CLUSTER SETSLOT <i> MIGRATING <target_id> 将更新 clusterState.migrating_slots_to[i] 的值设置为 target_id 所代表节点的 clusterNode 结构

- ACK 错误响应：客户端收到 ACK 错误后，会以错误提供的 IP 和 端口为目标发送 ASKING 命令，然后重新发送原本想要执行的命令

- ASKING 命令

  ![节点判断是否执行客户端命令的过程](http://redisbook1e-gallery.readthedocs.io/en/latest/_images/graphviz-b5c4a372c2e4808f4b355402bb92993399b93b1a.png)

## 复制与故障转移

### 设置从节点：CLUSTER REPLICATE <node_id>
1. 从节点更新 clusterState.myself.slaveof 指向的节点（该节点从 clusterState.nodes 中根据 node_id 查找）
2. 从节点更新 clusterState.myself.flags 属性
3. 对主节点进行复制

从节点(B)开始复制主节点(A)，该事件会通过消息发送给集群中其它节点，所有节点都会更新代表主节点(A)的clusterNode 结构的 slaves 属性和 numslaves 属性

### 故障检测

集群节点之间互相发送 PING 消息，如果没有及时收到回复则判定疑似下线。

节点通过互相发送消息方式交换集群个节点状态信息，下线信息保存在 clusterNode 的 fail_reports 链表

一个集群里板书以上负责处理槽的主节点都将每个主节点报告为疑似下线，那么这个主节点将被标记为已下线，并向集群广播该节点下线消息

### 故障转移

从节点发现自己的主节点已下线进行故障转移：
1. 选中一个从节点，基于 Raft 算法实现
2. 被选中的从节点执行 SLAVEOF no one 命令，成为新的主节点
3. 新主节点会撤销所有已下线主节点的槽指派，并重新指派给自己
4. 新主节点向集群广播一条 PONG 消息

## 消息

集群节点发的消息类型：
- MEET
- PING
- PONG
- FAIL
- PUBLISH

### 消息头
由 cluster.h/clusterMsg 结构表示

### 消息体
由 cluster.h/clusterMsgData 结构表示